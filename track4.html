<!DOCTYPE html>
<meta charset="utf-8">
<title>Redirecting to UG2+ 2024 Track 4 website</title>
<meta http-equiv="refresh" content="0; URL=https://cvpr2024ug2challenge.github.io/track4.html">
<link rel="canonical" href="https://cvpr2024ug2challenge.github.io/track4.html">
<html lang="en-US" dir="ltr">
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <!--  
    Document Title
    =============================================
  -->
  <title>UG2+ Challenge</title>
    <!--  
    Favicons
    =============================================
  -->
  <link rel="apple-touch-icon" sizes="57x57" href="assets/images/favicons/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="assets/images/favicons/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="assets/images/favicons/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="assets/images/favicons/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="assets/images/favicons/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="assets/images/favicons/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="assets/images/favicons/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="assets/images/favicons/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="assets/images/favicons/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192" href="assets/images/favicons/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="assets/images/favicons/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="assets/images/favicons/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="assets/images/favicons/favicon-16x16.png">
  <link rel="manifest" href="/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="assets/images/favicons/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
    <!--  
    Stylesheets
    =============================================
    
  -->
  <!-- Default stylesheets-->
  <link href="assets/lib/bootstrap/dist/css/bootstrap.min.css" rel="stylesheet">
  <!-- Template specific stylesheets-->
  <link href="https://fonts.googleapis.com/css?family=Roboto+Condensed:400,700" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Volkhov:400i" rel="stylesheet">
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,600,700,800" rel="stylesheet">
  <link href="assets/lib/animate.css/animate.css" rel="stylesheet">
  <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.6.3/css/all.css" integrity="sha384-UHRtZLI+pbxtHCWp1t77Bi1L4ZtiqrqD80Kn4Z8NTSRyMA2Fd33n5dQ8lWUE00s/" crossorigin="anonymous">
  <link href="assets/lib/et-line-font/et-line-font.css" rel="stylesheet">
  <link href="assets/lib/flexslider/flexslider.css" rel="stylesheet">
  <link href="assets/lib/owl.carousel/dist/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/lib/owl.carousel/dist/assets/owl.theme.default.min.css" rel="stylesheet">
  <link href="assets/lib/magnific-popup/dist/magnific-popup.css" rel="stylesheet">
  <link href="assets/lib/simple-text-rotator/simpletextrotator.css" rel="stylesheet">
  <!-- Main stylesheet and color file-->
  <link href="assets/css/style.css" rel="stylesheet">
  <link id="color-scheme" href="assets/css/colors/default.css" rel="stylesheet">
</head>
<style>
* {
  box-sizing: border-box;
}

.column {
  float: left;
  width: 24.0%;
  padding: 5px;
}

/* Clearfix (clear floats) */
.row::after {
  content: "";
  clear: both;
  display: table;
}
</style>
<body data-spy="scroll" data-target=".onpage-navigation" data-offset="60">
  <a id="ddmenuLink" href="menu_transparent.html">Menu</a>
  <main>
    <div class="page-loader">
      <div class="loader">Loading...</div>
    </div>


    <div class="main">
      <section class="module bg-dark-30 portfolio-page-header" data-background="assets/images/t2bg.jpg" style="padding: 30px 0;">
        <div class="container" style="width:100%">
          <div class="row" style="padding-top: 40px">
            <div class="col-sm-6 col-sm-offset-3">
              <!-- <p style="float: right;"><img height="300" width="300" src="pics/smoke_generator.png"></p> -->
              <h2 class="module-title font-alt" style="margin: 0 0 0px">Track 4: 3D reconstruction from low light/smoky videos</h2>
              <h3 class="module-subtitle font-serif" style="margin: 0 0 20px"><a href="https://docs.google.com/forms/d/e/1FAIpQLSepaa-sOJRAgwCG7V-ubR-lmuJKZx6gCj-YftFLCDAmc3CmEA/viewform?usp=sf_link" target="_blank" class="section-scroll btn btn-border-w btn-round">Register for this track</a></h3>
            </div>
          </div>
        </div>
      </section>


      <section class="module-medium" style="padding-bottom: 0px"></section>

      <!-- GT-RAIN Dataset Figure -->
      <div class="container" style="padding-bottom: 20px">
        <figure>
          <img src="assets/images/smoky_temp.PNG" style="width:75%;height:75%;margin-left:auto;margin-right:auto;display:block;border: none;">
          <figcaption style="width:80%;margin-left:auto;margin-right:auto;display:block;text-align: center;">
            <em>[Left] Visualization of the computer-aided design (CAD) model which we realize with Lego blocks. [Right two images] The realization of the CAD model viewed in the presence of artificial fog via UAV.. </em></figcaption>
        </figure>
    </div>


      
        <div class="container">
          <div class="row" style="text-align: justify">
            <div class="col-sm-12 font-nat" style="font-size: 13pt">
              <!--
              <p>Images captured in adverse weather conditions significantly impact the performance of many vision tasks. Rain is a common weather phenomenon that introduces visual degradations to captured images and videos through partial occlusions of objects – in heavy rain, severe occlusion to the background. As most vision algorithms assume clear weather, with no interference of rain, their performance suffers. Deraining is the task of removing such visual degradations so that the images are better suited to the assumptions of downstream vision algorithms, as well as for aesthetic fruition. </p>

              <p>UG<sup>2</sup>+ Track 3 aims to promote the development of novel single image deraining algorithms for real images. The competition will feature diverse and challenging scenarios that include (i) various types of rain conditions (i.e. long and short streaks, various densities and accumulation, with and without rain fog), (ii) large variety of background scenes from urban locations (i.e. buildings, streets, cityscapes) to natural scenery (i.e. forests, plains, hills), (iii) varying degrees of illumination from different times of day, and all of which are captured by (iv) cameras that cover a wide array of resolutions, noise levels, and intrinsic parameters. In a collaboration with the authors of GT-RAIN, we will introduce an additional 15 extra scenes set aside as a benchmark test set. The challenge will be split into three phases (training, validation, and testing), where data corresponding to each phase will be released to the participants. The validation set will consist of 5400 frames covering 18 scenes and the testing set 4500 frames covering 15 scenes. Unlike previous evaluation protocols that were limited to qualitative evaluation on real images, the submissions will be evaluated quantitatively using standard metrics like PSNR and SSIM. The ranking of algorithms will be determined based on evaluation scores on the testing set. The first place winner will be awarded $1000 USD, second place will be awarded $800 USD, and third place $500 USD. </p>
              -->

              <p>Computer vision in low visibility is a problem that faces many challenges and remains largely open. Visibility can be defined in various ways, such as in the case of low-light illumination or in the presence of amplitude scattering. With respect to low-light, Samsung, Google, and Apple are in constant competition aimed at providing the best low-light solution in the case of smartphone cameras. Amplitude scattering also provides a unique challenge in visibility because of the amount of ambient light present in the scene which is depth-dependent. In the case of self-driving cars or commercial UAVs, the ability of an optical system to see “through” the haze or fog present in real-world imaging is critical for making decisions which have significant impact on safety. In the case of handheld devices and small-to-moderately sized UAVs, the consideration of efficiency is a concern, both for reasons of computational capabilities on board as well as energy consumption.</p>

              <p>This challenge provides participants with videos captured in an environment filled with artificial fog. In particular, the videos captured in this challenge are from UAVs navigating the foggy environment. The structures are created purposefully using Lego blocks based on three-dimensional CAD (computer-aided design) models. We show an example of a particular CAD model in Figure 8. These structures may be placed together in a scene or as standalone objects with irregular shapes. Participants will be asked to reconstruct the three-dimensional representation of the object(s) in foggy videos captured by a UAV. We additionally visualize two captures from the UAV in Figure 8. The fog conditions are varied across captures along with the positioning of the UAV changing – this creates the observed degradation by the fog to be varying across the time of the capture.</p>

              <p>The contestants' solutions will be evaluated in two criteria: (1) accuracy and (2) execution time. The first measures whether the structures are correctly represented by the methods contributed by participants. This can be evaluated by virtue of ground truth available by CAD modeling. The second criteria aims to reflect the limitation of computational resources and energy efficiency faced by a device deployed in the real world, such as when the computer vision program needs to be executed on a UAV’s onboard processor. To measure the execution time, the contestants' programs will run on an embedded computer (Nvidia Jetson). The utility of the Jetson is that it offers an edge-device-like system with similar CUDA-related capabilities as a standard GPU. This makes overhead in moving research-level code to an edge device minimal.</p>

              <p>Submission criteria of this challenge require all participants to submit a fact sheet detailing their method, datasets used, runtime etc. The fact sheets will be compiled into a final report post challenge to highlight trends and innovative techniques. Participants are encouraged to submit manuscripts detailing their method to the workshop.</p>
                <!-- <ol>
                  <li>(Semi-)Supervised Object Detection in Haze Conditions</li>
                  <li>(Semi-)Supervised Face Detection in Low Light Conditions</li>
                </ol> -->
              
              <!-- <p style="text-align: justify; ">
                <!-- In all two sub-challenges, the participant teams are allowed to use external training data that are not mentioned above, including self-synthesized or self-collected data; -->
                <!-- <b>but they must state so in their submissions ("Method description" section in Codalab)</b>. -->
                <!-- Each leaderboard will be divided into two ranking lists: with and without external data. -->
                <!-- The ranking criteria will be the Mean average precision (mAP) on each testing set, with Interception-of-Union (IoU) threshold as 0.5. -->
                <!-- If the ratio of the intersection of a detected region with an annotated face region is greater than 0.5, a score of 1 is assigned to the detected region, and 0 otherwise. -->
                <!-- When mAPs with IoU as 0.5 are equal, the mAPs with higher IoUs (0.6, 0.7, 0.8) will be compared sequentially. -->
              <!-- </p> -->
              	<!-- <ul> -->


            </div>
          </div>

        </div>
      </section>
      <hr class="divider-w">

    <a id="ddfooterLink" href="footer.html">Footer</a>
      <div class="scroll-up"><a href="#totop"><i class="fa fa-angle-double-up"></i></a></div>
  </main>
    <!--  
    JavaScripts
    =============================================
    -->
    <script src="assets/lib/jquery/dist/jquery.js"></script>
    <script src="assets/lib/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="assets/lib/wow/dist/wow.js"></script>
    <script src="assets/lib/jquery.mb.ytplayer/dist/jquery.mb.YTPlayer.js"></script>
    <script src="assets/lib/isotope/dist/isotope.pkgd.js"></script>
    <script src="assets/lib/imagesloaded/imagesloaded.pkgd.js"></script>
    <!-- <script src="assets/lib/flexslider/jquery.flexslider.js"></script> -->
    <script src="assets/lib/owl.carousel/dist/owl.carousel.min.js"></script>
    <!-- <script src="assets/lib/smoothscroll.js"></script> -->
    <script src="assets/lib/magnific-popup/dist/jquery.magnific-popup.js"></script>
    <script src="assets/lib/simple-text-rotator/jquery.simple-text-rotator.min.js"></script>
    <script src="assets/js/plugins.js"></script>
    <script src="assets/js/main.js"></script>
    <script src="assets/js/ddmenu.js" type="text/javascript"></script>
    <script src="assets/js/ddfooter.js" type="text/javascript"></script>
</body>
</html>
